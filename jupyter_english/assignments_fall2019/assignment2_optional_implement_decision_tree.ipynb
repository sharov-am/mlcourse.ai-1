{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Author: [Yury Kashnitsky](https://yorko.github.io) (@yorko). Edited by Anna Tarelina (@feuerengel). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #2. Optional part\n",
    "## <center> Implementation of the decision tree algorithm\n",
    "    \n",
    "#  <center>  <font color = 'red'> Warning! </font>This is a very useful but ungraded assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix `random_state` (a.k.a. random seed) beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Implement the class `DecisionTree`**\n",
    "**Specification:**\n",
    "- the class is inherited from `sklearn.BaseEstimator`;\n",
    "- class constructor has the following parameters: \n",
    "    `max_depth` - maximum depth of the tree (`numpy.inf` by default); \n",
    "    `min_samples_split` - the minimum number of instances in a node for a splitting to be done (2 by default); \n",
    "    `criterion` - split criterion ('gini' or 'entropy' for classification, 'variance' or 'mad_median' for regression; 'gini' by default);\n",
    "    \n",
    "    A functional to be maximized to find an optimal partition at a given node has the form\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    where $X$ are samples at a given node, $X_l$ and $X_r$ are partitions of samples $X$ into two parts \n",
    "    with the following condition $[x_j < t]$, and $F(X)$ is a partition criterion.\n",
    "    \n",
    "    For classification: let $p_i$ be the fraction of the instances of the $i$-th class in the dataset $X$.\n",
    "    \n",
    "    'gini': Gini impurity $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Entropy $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    For regression: $y_j = y(x_j)$ - is a target for an instance $x_j$, $y = (y_1, \\dots, y_{|X|})$ - is a target vector.\n",
    "    \n",
    "    'variance': Variance (mean quadratic deviation from average) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Mean deviation from the median $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- the class has several methods: `fit`, `predict` and `predict_proba`;\n",
    "- the`fit` method takes the matrix of instances `X` and a target vector `y` (`numpy.ndarray` objects) and returns an instance of the class `DecisionTree` representing the decision tree trained on the dataset `(X, y)` according to parameters set in the constructor; \n",
    "- the `predict_proba` method takes the matrix of instances `X` and returns the matrix `P` of a size `X.shape[0] x K`, where `K` is the number of classes and $p_{ij}$ is the probability of an instance in $i$-th row of `X` to belong to class $j \\in \\{1, \\dots, K\\}$.\n",
    "- the `predict` method takes the matrix of instances `X` and returns a prediction vector; in case of classification, prediction for an instance $x_i$ falling into leaf $L$ will be the class, mostly represented among instances in $L$. In case of regression, it'll be the mean value of targets for all instances in leaf $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy1(y):    \n",
    "    e = 0\n",
    "    for v in y:\n",
    "        e += -v *np.log2(v)\n",
    "\n",
    "def gini(y):\n",
    "    sum = 0\n",
    "    for i in y:\n",
    "        sum += i**2\n",
    "    return 1 - sum    \n",
    "\n",
    "def variance(y):\n",
    "     return np.var(y) \n",
    "\n",
    "def mad_median(y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` class implements a node in the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'feature index = {0},threshold ={1},[{2},{3}]'.format(self.feature_idx, self.threshold, len((self.left)), len((self.right)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the function for calculating a prediction in a leaf. For regression, let's take the mean for all values in a leaf, for classification - the most popular class in leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        if self.left_child is None:\n",
    "            left = \"\"\n",
    "        else:\n",
    "            left = \"\\r\\n\" + str(self.left_child)\n",
    "\n",
    "        if self.right_child is None:\n",
    "            right = \"\"\n",
    "        else:\n",
    "            right = \"\\r\\n\" + str(self.right_child)\n",
    "\n",
    "        if self.root_node is None:\n",
    "            current = \"\"\n",
    "        else:\n",
    "            current = str(self.root_node)\n",
    "        return current + left + right\n",
    "\n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2,\n",
    "                 criterion='gini', debug=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        if criterion == 'gini':\n",
    "            self.crit = gini\n",
    "        else:\n",
    "            self.crit = entropy\n",
    "\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.root_node = None\n",
    "        self.debug = debug\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        global node_counter\n",
    "\n",
    "        if len(y) < self.min_samples_split:\n",
    "            self.root_node = Node(-1, -1, 'leaf', y, [0])\n",
    "            self.root_node.counter = node_counter\n",
    "            node_counter += 1\n",
    "            self.right_child = None\n",
    "            self.left_child = None\n",
    "            return self\n",
    "\n",
    "        max_q = float(\"-inf\")\n",
    "        best_split_value = None\n",
    "        best_feature = None\n",
    "\n",
    "        for f in range(X.shape[1]):\n",
    "            x_col = X[:, f]\n",
    "            splits = self._find_splits(x_col)\n",
    "\n",
    "            for spl in splits:\n",
    "\n",
    "                # разбиваю данные по нацлучшему критерию\n",
    "                q, _, _ = self._regression_var_criterion(X, f, y, spl)\n",
    "                if q > max_q:\n",
    "                    max_q = q\n",
    "                    best_feature = f\n",
    "                    best_split_value = spl\n",
    "\n",
    "        if best_feature is None:\n",
    "            return None\n",
    "\n",
    "        X_left, X_right, y_l, y_r = self._get_data_split(X, y, best_feature, best_split_value)\n",
    "\n",
    "        assert X_left is not None\n",
    "        assert X_right is not None\n",
    "\n",
    "        if self.max_depth == 0:\n",
    "            self.root_node = Node(best_feature, best_split_value, 'leaf', y_l, y_r)\n",
    "            self.root_node.counter = node_counter\n",
    "            node_counter += 1\n",
    "            self.left_child = None\n",
    "            self.right_child = None\n",
    "            return self\n",
    "\n",
    "        new_depth = self.max_depth\n",
    "        if new_depth != np.inf:\n",
    "            new_depth -= 1\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"call left branch with X_left.shape = {0}, len(y_l) = {1}\".format(X_left.shape, len(y_l)))\n",
    "\n",
    "        left_tree = DecisionTree(max_depth=new_depth, min_samples_split=self.min_samples_split,\n",
    "                                 criterion=self.criterion, debug=self.debug)\n",
    "        self.left_child = left_tree.fit(X_left, y_l)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"call right branch with X_right.shape = {0}, len(y_r) = {1}\".format(X_right.shape, len(y_r)))\n",
    "\n",
    "        right_tree = DecisionTree(max_depth=new_depth, min_samples_split=self.min_samples_split,\n",
    "                                  criterion=self.criterion, debug=self.debug)\n",
    "        self.right_child = right_tree.fit(X_right, y_r)\n",
    "\n",
    "        self.root_node = Node(best_feature, best_split_value, str(best_feature), y_l, y_r)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "\n",
    "            cur_tree = self\n",
    "            leaf = cur_tree.root_node\n",
    "            while cur_tree is not None:\n",
    "\n",
    "                leaf = cur_tree.root_node\n",
    "\n",
    "                assert leaf is not None, \"leaf.root_node is not None\"\n",
    "\n",
    "                if x[cur_tree.root_node.feature_idx] < cur_tree.root_node.threshold:\n",
    "                    cur_tree = cur_tree.left_child\n",
    "                else:\n",
    "                    cur_tree = cur_tree.right_child\n",
    "\n",
    "            assert leaf is not None, \"leaf is not None\"\n",
    "#            assert leaf.labels == 'leaf', \"leaf.labels =='leaf'\"\n",
    "\n",
    "            if isinstance(x, pd.DataFrame):\n",
    "                type = X.dtypes[leaf.feature_idx]\n",
    "                if type == 'object':\n",
    "                    predictions.append(self.most_frequent(np.append(leaf.left, leaf.right)))\n",
    "                else:\n",
    "                    predictions.append(np.mean(np.append(leaf.left, leaf.right)))\n",
    "            else:\n",
    "                predictions.append(self._most_frequent(list(np.append(leaf.left, leaf.right))))\n",
    "        return predictions\n",
    "\n",
    "    def predict_leaf_number(self, x):\n",
    "        predictions = []\n",
    "\n",
    "        cur_tree = self\n",
    "        leaf = cur_tree.root_node\n",
    "        while cur_tree is not None:\n",
    "\n",
    "            leaf = cur_tree.root_node\n",
    "\n",
    "            assert leaf is not None, \"leaf.root_node is not None\"\n",
    "\n",
    "            if x[cur_tree.root_node.feature_idx] < cur_tree.root_node.threshold:\n",
    "                cur_tree = cur_tree.left_child\n",
    "            else:\n",
    "                cur_tree = cur_tree.right_child\n",
    "\n",
    "        assert leaf is not None, \"leaf is not None\"\n",
    "        assert leaf.labels == 'leaf', \"leaf.labels =='leaf'\"\n",
    "        assert leaf.counter >= 0 , \"leaf.counter >= 0\"\n",
    "        return leaf.counter\n",
    "\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        K = self.count_leafs()\n",
    "        result = []\n",
    "        i = 0\n",
    "        for x in X:\n",
    "            num = self.predict_leaf_number(x)\n",
    "            t = np.zeros(K)\n",
    "            t[num] = 1\n",
    "            result.append(t)\n",
    "        return  np.reshape(result,(X.shape[0],K))\n",
    "\n",
    "\n",
    "\n",
    "    def _find_splits(self, X):\n",
    "        \"\"\"Find all possible split values.\"\"\"\n",
    "        split_values = set()\n",
    "\n",
    "        # Get unique values in a sorted order\n",
    "        x_unique = list(np.unique(X))\n",
    "        for i in range(1, len(x_unique)):\n",
    "            # Find a point between two values\n",
    "            average = (x_unique[i - 1] + x_unique[i]) / 2.0\n",
    "            split_values.add(average)\n",
    "\n",
    "        return list(split_values)\n",
    "\n",
    "    def _most_frequent(self, lst):\n",
    "        return max(set(lst), key=lst.count)\n",
    "\n",
    "    def _regression_var_criterion(self, X, feature, y, t):\n",
    "        x_col_values = X[:, feature]\n",
    "\n",
    "        assert X.shape[0] == len(x_col_values), \"X.shape[0] == len(x_col_values)\"\n",
    "        assert X.shape[0] == len(y), \"X.shape[0] == len(y)\"\n",
    "        # print('feature = {0}, X.shape[1] = {1}'.format(feature,X.shape[1]))\n",
    "        y_l = [y[i] for i, val in enumerate(x_col_values) if val < t]\n",
    "        y_r = [y[i] for i, val in enumerate(x_col_values) if val >= t]\n",
    "        q = np.var(y) - len(y_l) / len(y) * self.crit(y_l) - len(y_r) / len(y) * self.crit(y_r)\n",
    "\n",
    "        assert len(y_l) + len(y_r) == len(y)\n",
    "        assert len(y_l) != 0 and len(y_r) != 0, \"len(y_l) == 0 or len(y_r) == 0\"\n",
    "\n",
    "        return q, y_l, y_r\n",
    "\n",
    "    def _get_data_split(self, X, y, feature, threshold):\n",
    "\n",
    "        x_col_values = X[:, feature]  #\n",
    "        assert X.shape[0] == len(x_col_values), \"X.shape[0] == len(x_col_values)\"\n",
    "        assert X.shape[0] == len(y), \"X.shape[0] == len(y)\"\n",
    "        # print('feature = {0}, X.shape[1] = {1}'.format(feature,X.shape[1]))\n",
    "        y_l = [y[i] for i, val in enumerate(x_col_values) if val < threshold]\n",
    "        y_r = [y[i] for i, val in enumerate(x_col_values) if val >= threshold]\n",
    "        X_l = X[X[:, feature] < threshold]\n",
    "        X_r = X[X[:, feature] >= threshold]\n",
    "\n",
    "        assert len(y_l) + len(y_r) == len(y), \"len(y_l) + len(y_r) == len(y)\"\n",
    "        assert X_l.shape[0] + X_r.shape[0] == X.shape[0], \"X_l.shape[0] + X_r.shape[0] == X.shape[0]\"\n",
    "        return X_l, X_r, y_l, y_r\n",
    "\n",
    "    def count_leafs(self):\n",
    "        if self.root_node.labels == 'leaf':\n",
    "            return 1\n",
    "        else:\n",
    "            sum = 0\n",
    "            if self.left_child is not None:\n",
    "                sum += self.left_child.count_leafs()\n",
    "            if self.right_child is not None:\n",
    "                sum += self.right_child.count_leafs()\n",
    "            return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the implemented algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `digits` using the method `load_digits`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, and `random_state=17`. Try to train shallow decision trees and make sure that gini and entropy criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use range(3, 11), for criterion use {'gini', 'entropy'}. Quality measure is `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n"
     ]
    }
   ],
   "source": [
    "tree_params = {'max_depth': list(range(3, 11)),'criterion': ['gini']}\n",
    "tree_grid = GridSearchCV(DecisionTree(), tree_params, cv=5, scoring='accuracy')\n",
    "tree_grid.fit(X_train,y_train)\n",
    "print('fit done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `accuracy` for criteria `gini` and `entropy` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_estimator_': DecisionTree(criterion='gini', debug=False, max_depth=4, min_samples_split=2),\n",
      " 'best_index_': 1,\n",
      " 'best_params_': {'criterion': 'gini', 'max_depth': 4},\n",
      " 'best_score_': 0.08698677800974251,\n",
      " 'cv': 5,\n",
      " 'cv_results_': {'mean_fit_time': array([ 4.87908783,  5.99319925,  7.43594346,  8.36003594,  9.37113705,\n",
      "       10.17541742, 12.63246307, 12.81308126]),\n",
      "                 'mean_score_time': array([0.17261734, 0.16041598, 0.16981702, 0.16401634, 0.16021595,\n",
      "       0.15521545, 0.16521654, 0.16601653]),\n",
      "                 'mean_test_score': array([0.08350731, 0.08698678, 0.08698678, 0.08698678, 0.08629088,\n",
      "       0.08629088, 0.08629088, 0.08698678]),\n",
      "                 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      "                 'param_max_depth': masked_array(data=[3, 4, 5, 6, 7, 8, 9, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      "                 'params': [{'criterion': 'gini', 'max_depth': 3},\n",
      "                            {'criterion': 'gini', 'max_depth': 4},\n",
      "                            {'criterion': 'gini', 'max_depth': 5},\n",
      "                            {'criterion': 'gini', 'max_depth': 6},\n",
      "                            {'criterion': 'gini', 'max_depth': 7},\n",
      "                            {'criterion': 'gini', 'max_depth': 8},\n",
      "                            {'criterion': 'gini', 'max_depth': 9},\n",
      "                            {'criterion': 'gini', 'max_depth': 10}],\n",
      "                 'rank_test_score': array([8, 1, 1, 1, 5, 5, 5, 1], dtype=int32),\n",
      "                 'split0_test_score': array([0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.08333333,\n",
      "       0.08333333, 0.08333333, 0.08333333]),\n",
      "                 'split1_test_score': array([0.07291667, 0.09027778, 0.09027778, 0.09027778, 0.09027778,\n",
      "       0.09027778, 0.09027778, 0.09027778]),\n",
      "                 'split2_test_score': array([0.09407666, 0.09407666, 0.09407666, 0.09407666, 0.09059233,\n",
      "       0.09059233, 0.09059233, 0.09059233]),\n",
      "                 'split3_test_score': array([0.08710801, 0.08710801, 0.08710801, 0.08710801, 0.08710801,\n",
      "       0.08710801, 0.08710801, 0.08710801]),\n",
      "                 'split4_test_score': array([0.08013937, 0.08013937, 0.08013937, 0.08013937, 0.08013937,\n",
      "       0.08013937, 0.08013937, 0.08362369]),\n",
      "                 'std_fit_time': array([0.14505733, 0.0967581 , 0.31091786, 0.24220879, 0.27882472,\n",
      "       0.1621662 , 1.33613514, 0.53973261]),\n",
      "                 'std_score_time': array([0.02690699, 0.00842952, 0.02613613, 0.01362485, 0.00856591,\n",
      "       0.00381623, 0.01473108, 0.00918782]),\n",
      "                 'std_test_score': array([0.00704636, 0.00492466, 0.00492466, 0.00492466, 0.00404044,\n",
      "       0.00404044, 0.00404044, 0.00311513])},\n",
      " 'error_score': 'raise-deprecating',\n",
      " 'estimator': DecisionTree(criterion='gini', debug=False, max_depth=inf, min_samples_split=2),\n",
      " 'iid': 'warn',\n",
      " 'multimetric_': False,\n",
      " 'n_jobs': None,\n",
      " 'n_splits_': 5,\n",
      " 'param_grid': {'criterion': ['gini'], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10]},\n",
      " 'pre_dispatch': '2*n_jobs',\n",
      " 'refit': True,\n",
      " 'refit_time_': 7.083708047866821,\n",
      " 'return_train_score': False,\n",
      " 'scorer_': make_scorer(accuracy_score),\n",
      " 'scoring': 'accuracy',\n",
      " 'verbose': 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(tree_grid))\n",
    "\n",
    "plt.plot(tree_params['max_depth'], \n",
    "         tree_grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Mean CV accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose all correct statements:**\n",
    "1. Optimal value of the `max_depth` parameter is on the interval [4, 9] for both criteria.\n",
    "2. Created plots have no intersection on the interval [3, 10]\n",
    "3. Created plots intersect each other only once on the interval [3, 10].\n",
    "4. The best quality for `max_depth` on the interval [3, 10] is reached using `gini` criterion .\n",
    "5. Accuracy is strictly increasing at least for one of the criteria, when `max_depth` is also increasing on the interval [3, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the optimal values for max_depth and criterion parameters?**\n",
    "1. max_depth = 7, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 9, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train decision tree on `(X_train, y_train)` using the optimal values of `max_depth` and `criterion`. Compute class probabilities for `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(max_depth = 8,criterion = 'entropy')\n",
    "tree = dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the given matrix, compute the mean class probabilities for all instances in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tree.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the maximum probability in a resulted vector?**\n",
    "1. 0.127\n",
    "2. 0.118\n",
    "3. 1.0\n",
    "4. 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `boston` using the method `load_boston`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, `random_state=17`. Try to train shallow regression decision trees and make sure that `variance` and `mad_median` criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use `range(2, 9)`, for `criterion` use {'variance', 'mad_median'}. Quality measure is `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `neg_mean_squared_error` for criteria `variance` and `mad_median` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Choose all correct statements:**\n",
    "1. Created plots have no intersection on the interval [2, 8].\n",
    "2. Created plots intersect each other only once on the interval [2, 8].\n",
    "3. Optimal value of the `max_depth` for each of the criteria is on the border of the interval [2, 8].\n",
    "4. The best quality at `max_depth` on the interval [2, 8] is reached using `mad_median` criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What are the optimal values for `max_depth` and `criterion` parameters?**\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 5, criterion = 'variance'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
